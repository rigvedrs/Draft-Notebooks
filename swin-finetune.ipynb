{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3805,"sourceType":"modelInstanceVersion","modelInstanceId":2708},{"sourceId":3806,"sourceType":"modelInstanceVersion","modelInstanceId":2709},{"sourceId":3807,"sourceType":"modelInstanceVersion","modelInstanceId":2710},{"sourceId":3814,"sourceType":"modelInstanceVersion","modelInstanceId":2717},{"sourceId":3815,"sourceType":"modelInstanceVersion","modelInstanceId":2718},{"sourceId":3816,"sourceType":"modelInstanceVersion","modelInstanceId":2719},{"sourceId":3817,"sourceType":"modelInstanceVersion","modelInstanceId":2720},{"sourceId":3818,"sourceType":"modelInstanceVersion","modelInstanceId":2721},{"sourceId":3819,"sourceType":"modelInstanceVersion","modelInstanceId":2722},{"sourceId":3824,"sourceType":"modelInstanceVersion","modelInstanceId":2727},{"sourceId":3825,"sourceType":"modelInstanceVersion","modelInstanceId":2728},{"sourceId":3826,"sourceType":"modelInstanceVersion","modelInstanceId":2729},{"sourceId":3827,"sourceType":"modelInstanceVersion","modelInstanceId":2730}],"dockerImageVersionId":30388,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"id":"89B27-TGiDNB"}},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\n\ntfds.disable_progress_bar()\n\nimport os\nimport sys\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"id":"9u3d4Z7uQsmp","execution":{"iopub.status.busy":"2024-01-24T20:02:30.413350Z","iopub.execute_input":"2024-01-24T20:02:30.413816Z","iopub.status.idle":"2024-01-24T20:02:41.357133Z","shell.execute_reply.started":"2024-01-24T20:02:30.413724Z","shell.execute_reply":"2024-01-24T20:02:41.355231Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Copied from:\n# https://weepingfish.github.io/2020/07/22/0722-suppress-tensorflow-warnings/\n\n# Filter tensorflow version warnings\n\n# https://stackoverflow.com/questions/40426502/is-there-a-way-to-suppress-the-messages-tensorflow-prints/40426709\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # or any {'0', '1', '2'}\nimport warnings\n\n# https://stackoverflow.com/questions/15777951/how-to-suppress-pandas-future-warning\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\ntf.get_logger().setLevel(\"INFO\")\ntf.autograph.set_verbosity(0)\nimport logging\n\ntf.get_logger().setLevel(logging.ERROR)","metadata":{"id":"mdUDP5qIiG05","execution":{"iopub.status.busy":"2024-01-24T20:03:09.934567Z","iopub.execute_input":"2024-01-24T20:03:09.936086Z","iopub.status.idle":"2024-01-24T20:03:09.944275Z","shell.execute_reply.started":"2024-01-24T20:03:09.936036Z","shell.execute_reply":"2024-01-24T20:03:09.942787Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## GPUs","metadata":{"id":"mPo10cahZXXQ"}},{"cell_type":"code","source":"try:  # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()  # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:  # detect GPUs\n    tpu = False\n    strategy = (\n        tf.distribute.get_strategy()\n    )  # default strategy that works on CPU and single GPU\nprint(\"Number of Accelerators: \", strategy.num_replicas_in_sync)","metadata":{"id":"FpvUOuC3j27n","execution":{"iopub.status.busy":"2024-01-24T20:03:14.439455Z","iopub.execute_input":"2024-01-24T20:03:14.439905Z","iopub.status.idle":"2024-01-24T20:03:14.460312Z","shell.execute_reply.started":"2024-01-24T20:03:14.439865Z","shell.execute_reply":"2024-01-24T20:03:14.459374Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of Accelerators:  1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Configuration\n\nFind the list of all fine-tunable models [here](https://www.kaggle.com/models/spsayakpaul/swin).","metadata":{"id":"w9S3uKC_iXY5"}},{"cell_type":"code","source":"# Model\nIMAGE_SIZE = [224, 224] # Change this accordingly. \nMODEL_PATH = \"/kaggle/input/swin/tensorflow2/tiny-patch4-window7-224-fe/1\" \n\n# TPU\nif tpu:\n    BATCH_SIZE = (\n        16 * strategy.num_replicas_in_sync\n    )  # a TPU has 8 cores so this will be 128\nelse:\n    BATCH_SIZE = 64\n\n# Dataset\nCLASSES = [\n    \"dandelion\",\n    \"daisy\",\n    \"tulips\",\n    \"sunflowers\",\n    \"roses\",\n]  # don't change the order\n\n# Other constants\nMEAN = tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])  # imagenet mean\nSTD = tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])  # imagenet std\nAUTO = tf.data.AUTOTUNE","metadata":{"id":"kCc6tdUGnD4C","execution":{"iopub.status.busy":"2024-01-24T20:03:17.179222Z","iopub.execute_input":"2024-01-24T20:03:17.179665Z","iopub.status.idle":"2024-01-24T20:03:17.221947Z","shell.execute_reply.started":"2024-01-24T20:03:17.179617Z","shell.execute_reply":"2024-01-24T20:03:17.220856Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Data Pipeline\n\n[DeiT authors](https://arxiv.org/abs/2012.12877) use a separate preprocessing pipeline for fine-tuning. But for keeping this walkthrough short and simple, we can just perform the basic ones.","metadata":{"id":"9iTImGI5qMQT"}},{"cell_type":"code","source":"def make_dataset(dataset: tf.data.Dataset, train: bool, image_size: int = IMAGE_SIZE):\n    def preprocess(image, label):\n        # for training, do augmentation\n        if train:\n            if tf.random.uniform(shape=[]) > 0.5:\n                image = tf.image.flip_left_right(image)\n        image = tf.image.resize(image, size=image_size, method=\"bicubic\")\n        image = (image - MEAN) / STD  # normalization\n        return image, label\n\n    if train:\n        dataset = dataset.shuffle(BATCH_SIZE * 10)\n\n    return dataset.map(preprocess, AUTO).batch(BATCH_SIZE).prefetch(AUTO)","metadata":{"id":"h29TLx7gqN_7","execution":{"iopub.status.busy":"2023-02-23T19:58:05.27429Z","iopub.execute_input":"2023-02-23T19:58:05.27547Z","iopub.status.idle":"2023-02-23T19:58:05.291399Z","shell.execute_reply.started":"2023-02-23T19:58:05.275433Z","shell.execute_reply":"2023-02-23T19:58:05.290278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Flower Dataset","metadata":{"id":"AMQ3Qs9_pddU"}},{"cell_type":"code","source":"train_dataset, val_dataset = tfds.load(\n    \"tf_flowers\",\n    split=[\"train[:90%]\", \"train[90%:]\"],\n    as_supervised=True,\n    try_gcs=False,  # gcs_path is necessary for tpu,\n)\n\nnum_train = tf.data.experimental.cardinality(train_dataset)\nnum_val = tf.data.experimental.cardinality(val_dataset)\nprint(f\"Number of training examples: {num_train}\")\nprint(f\"Number of validation examples: {num_val}\")","metadata":{"id":"M3G-2aUBQJ-H","execution":{"iopub.status.busy":"2023-02-23T19:58:05.292976Z","iopub.execute_input":"2023-02-23T19:58:05.294121Z","iopub.status.idle":"2023-02-23T19:58:05.412483Z","shell.execute_reply.started":"2023-02-23T19:58:05.294085Z","shell.execute_reply":"2023-02-23T19:58:05.411487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# My dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:17:22.049208Z","iopub.execute_input":"2024-01-24T20:17:22.049619Z","iopub.status.idle":"2024-01-24T20:17:22.055335Z","shell.execute_reply.started":"2024-01-24T20:17:22.049588Z","shell.execute_reply":"2024-01-24T20:17:22.053822Z"}}},{"cell_type":"code","source":"import os\nfrom sklearn.model_selection import train_test_split\n\n# Define dataset paths\ndataset_path = \"/kaggle/input/dataset\"\n\n# Create a list to store image paths and labels\nimage_paths = []\nlabels = []\n\n# Iterate over each class folder\nfor class_label, class_name in enumerate(os.listdir(os.path.join(dataset_path, \"train\"))):\n    class_path = os.path.join(dataset_path, \"train\", class_name)\n    \n    # Iterate over each image in the class folder\n    for image_name in os.listdir(class_path):\n        image_path = os.path.join(class_path, image_name)\n        image_paths.append(image_path)\n        labels.append(class_label)\n\n# Split the dataset into train and validation sets\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    image_paths, labels, test_size=0.1, random_state=42\n)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\nval_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_path, label):\n    # Read and decode the image\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_image(image, channels=3)\n    # You can add additional preprocessing here if needed\n    return image, label\n\n# Apply the load_image function to the datasets\ntrain_dataset = train_dataset.map(load_image)\nval_dataset = val_dataset.map(load_image)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the TFDS-style datasets\ntrain_dataset, val_dataset = tfds.load(\n    \"your_dataset_name\",\n    split=[\"train[:90%]\", \"train[90%:]\"],\n    as_supervised=True,\n    try_gcs=False,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare dataset","metadata":{"id":"l2X7sE3oRLXN"}},{"cell_type":"code","source":"train_dataset = make_dataset(train_dataset, True)\nval_dataset = make_dataset(val_dataset, False)","metadata":{"id":"oftrfYw1qXei","execution":{"iopub.status.busy":"2023-02-23T19:58:05.416634Z","iopub.execute_input":"2023-02-23T19:58:05.419233Z","iopub.status.idle":"2023-02-23T19:58:05.601426Z","shell.execute_reply.started":"2023-02-23T19:58:05.419192Z","shell.execute_reply":"2023-02-23T19:58:05.600411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize","metadata":{"id":"kNyCCM6PRM8I"}},{"cell_type":"code","source":"sample_images, sample_labels = next(iter(train_dataset))\n\nplt.figure(figsize=(5 * 3, 3 * 3))\nfor n in range(15):\n    ax = plt.subplot(3, 5, n + 1)\n    image = (sample_images[n] * STD + MEAN).numpy()\n    image = (image - image.min()) / (\n        image.max() - image.min()\n    )  # convert to [0, 1] for avoiding matplotlib warning\n    plt.imshow(image)\n    plt.title(CLASSES[sample_labels[n]])\n    plt.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"id":"IaGzFUUVqjaC","execution":{"iopub.status.busy":"2023-02-23T19:58:05.606098Z","iopub.execute_input":"2023-02-23T19:58:05.608598Z","iopub.status.idle":"2023-02-23T19:58:08.921389Z","shell.execute_reply.started":"2023-02-23T19:58:05.608561Z","shell.execute_reply":"2023-02-23T19:58:08.920354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LR Scheduler Utility","metadata":{"id":"Qf6u_7tt8BYy"}},{"cell_type":"code","source":"# Reference:\n# https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2\n\n\nclass WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(\n        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n    ):\n        super(WarmUpCosine, self).__init__()\n\n        self.learning_rate_base = learning_rate_base\n        self.total_steps = total_steps\n        self.warmup_learning_rate = warmup_learning_rate\n        self.warmup_steps = warmup_steps\n        self.pi = tf.constant(np.pi)\n\n    def __call__(self, step):\n        if self.total_steps < self.warmup_steps:\n            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n        learning_rate = (\n            0.5\n            * self.learning_rate_base\n            * (\n                1\n                + tf.cos(\n                    self.pi\n                    * (tf.cast(step, tf.float32) - self.warmup_steps)\n                    / float(self.total_steps - self.warmup_steps)\n                )\n            )\n        )\n\n        if self.warmup_steps > 0:\n            if self.learning_rate_base < self.warmup_learning_rate:\n                raise ValueError(\n                    \"Learning_rate_base must be larger or equal to \"\n                    \"warmup_learning_rate.\"\n                )\n            slope = (\n                self.learning_rate_base - self.warmup_learning_rate\n            ) / self.warmup_steps\n            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n            learning_rate = tf.where(\n                step < self.warmup_steps, warmup_rate, learning_rate\n            )\n        return tf.where(\n            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n        )","metadata":{"id":"oVTbnkJL79T_","execution":{"iopub.status.busy":"2023-02-23T19:58:08.925067Z","iopub.execute_input":"2023-02-23T19:58:08.925735Z","iopub.status.idle":"2023-02-23T19:58:08.946988Z","shell.execute_reply.started":"2023-02-23T19:58:08.92568Z","shell.execute_reply":"2023-02-23T19:58:08.945471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Utility","metadata":{"id":"ALtRUlxhw8Vt"}},{"cell_type":"code","source":"def get_model(model_url: str, res: int = IMAGE_SIZE[0], num_classes: int = 5) -> tf.keras.Model:\n    inputs = tf.keras.Input((res, res, 3))\n    hub_module = hub.KerasLayer(model_url, trainable=True)\n\n    x = hub_module(inputs, training=False) \n    outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    return tf.keras.Model(inputs, outputs)","metadata":{"id":"JD9SI_Q9JdAB","execution":{"iopub.status.busy":"2023-02-23T19:58:08.951467Z","iopub.execute_input":"2023-02-23T19:58:08.954053Z","iopub.status.idle":"2023-02-23T19:58:08.967533Z","shell.execute_reply.started":"2023-02-23T19:58:08.954015Z","shell.execute_reply":"2023-02-23T19:58:08.966524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_model(MODEL_PATH).summary()","metadata":{"id":"wpZApp9u9_Y-","execution":{"iopub.status.busy":"2023-02-23T19:58:08.969044Z","iopub.execute_input":"2023-02-23T19:58:08.969882Z","iopub.status.idle":"2023-02-23T19:58:29.874279Z","shell.execute_reply.started":"2023-02-23T19:58:08.969846Z","shell.execute_reply":"2023-02-23T19:58:29.873317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Hyperparameters","metadata":{"id":"dMfenMQcxAAb"}},{"cell_type":"code","source":"EPOCHS = 10\nWARMUP_STEPS = 10\nINIT_LR = 0.03\nWAMRUP_LR = 0.006\n\nTOTAL_STEPS = int((num_train / BATCH_SIZE) * EPOCHS)\n\nscheduled_lrs = WarmUpCosine(\n    learning_rate_base=INIT_LR,\n    total_steps=TOTAL_STEPS,\n    warmup_learning_rate=WAMRUP_LR,\n    warmup_steps=WARMUP_STEPS,\n)","metadata":{"id":"1D7Iu7oD8WzX","execution":{"iopub.status.busy":"2023-02-23T19:58:29.87575Z","iopub.execute_input":"2023-02-23T19:58:29.876952Z","iopub.status.idle":"2023-02-23T19:58:29.884525Z","shell.execute_reply.started":"2023-02-23T19:58:29.876914Z","shell.execute_reply":"2023-02-23T19:58:29.88331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = keras.optimizers.SGD(scheduled_lrs)\nloss = keras.losses.SparseCategoricalCrossentropy()","metadata":{"id":"M-ID7vP5mIKs","execution":{"iopub.status.busy":"2023-02-23T19:58:29.886746Z","iopub.execute_input":"2023-02-23T19:58:29.887594Z","iopub.status.idle":"2023-02-23T19:58:29.893412Z","shell.execute_reply.started":"2023-02-23T19:58:29.88756Z","shell.execute_reply":"2023-02-23T19:58:29.89263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training & Validation","metadata":{"id":"E9p4ymNh9y7d"}},{"cell_type":"code","source":"with strategy.scope(): # this line is all that is needed to run on TPU (or multi-GPU, ...)\n    model = get_model(MODEL_PATH)\n    model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n\nhistory = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)","metadata":{"id":"VnZTSd8K90Mq","execution":{"iopub.status.busy":"2023-02-23T19:58:29.894352Z","iopub.execute_input":"2023-02-23T19:58:29.896049Z","iopub.status.idle":"2023-02-23T20:05:52.499666Z","shell.execute_reply.started":"2023-02-23T19:58:29.896011Z","shell.execute_reply":"2023-02-23T20:05:52.498673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(history.history)\nfig, ax = plt.subplots(2, 1, figsize=(10, 10))\nresult[[\"accuracy\", \"val_accuracy\"]].plot(xlabel=\"epoch\", ylabel=\"score\", ax=ax[0])\nresult[[\"loss\", \"val_loss\"]].plot(xlabel=\"epoch\", ylabel=\"score\", ax=ax[1])","metadata":{"id":"jc7LMVz5Cbx6","execution":{"iopub.status.busy":"2023-02-23T20:05:52.502096Z","iopub.execute_input":"2023-02-23T20:05:52.502452Z","iopub.status.idle":"2023-02-23T20:05:52.94303Z","shell.execute_reply.started":"2023-02-23T20:05:52.502416Z","shell.execute_reply":"2023-02-23T20:05:52.942015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{"id":"MKFMWzh0Yxsq"}},{"cell_type":"code","source":"sample_images, sample_labels = next(iter(val_dataset))\n\npredictions = model.predict(sample_images, batch_size=16).argmax(axis=-1)\nevaluations = model.evaluate(sample_images, sample_labels, batch_size=16)\n\nprint(\"[val_loss, val_acc]\", evaluations)","metadata":{"id":"yMEsR851VDZb","execution":{"iopub.status.busy":"2023-02-23T20:05:52.944605Z","iopub.execute_input":"2023-02-23T20:05:52.945237Z","iopub.status.idle":"2023-02-23T20:05:55.581198Z","shell.execute_reply.started":"2023-02-23T20:05:52.945197Z","shell.execute_reply":"2023-02-23T20:05:55.580293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5 * 3, 3 * 3))\nfor n in range(15):\n    ax = plt.subplot(3, 5, n + 1)\n    image = (sample_images[n] * STD + MEAN).numpy()\n    image = (image - image.min()) / (\n        image.max() - image.min()\n    )  # convert to [0, 1] for avoiding matplotlib warning\n    plt.imshow(image)\n    target = CLASSES[sample_labels[n]]\n    pred = CLASSES[predictions[n]]\n    plt.title(\"{} ({})\".format(target, pred))\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"qzCCDL1CZFx6","execution":{"iopub.status.busy":"2023-02-23T20:05:55.582993Z","iopub.execute_input":"2023-02-23T20:05:55.583405Z","iopub.status.idle":"2023-02-23T20:05:57.118466Z","shell.execute_reply.started":"2023-02-23T20:05:55.583369Z","shell.execute_reply":"2023-02-23T20:05:57.117626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\n* [Keras Flowers on TPU (solution)](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_solution.ipynb)\n\n\nThis notebook is copied and modified from [here](https://github.com/sayakpaul/ConvNeXt-TF/blob/main/notebooks/finetune.ipynb). I'm thankful to [awsaf49](https://github.com/awsaf49) who originally worked on that notebook. ","metadata":{"id":"2e5oy9zmNNID"}},{"cell_type":"markdown","source":"Credit: https://github.com/sayakpaul/swin-transformers-tf/blob/main/notebooks/finetune.ipynb","metadata":{}}]}